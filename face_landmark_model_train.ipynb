{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face-landmark-model-train.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOm1a5Y7ZaTNts/sXHKsmET",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthick47v2/mock-buddy/blob/main/face_landmark_model_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S0G29V62A0F-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d40c3d9b-f8d5-4eed-fd4a-4af06f7eeaa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.model_selection\n",
        "import tensorflow\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "7SaYdrGEB1P4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.load('/content/gdrive/MyDrive/data-v/y_train30.npy')\n",
        "frames = np.load('/content/gdrive/MyDrive/data-v/frames30.npy')"
      ],
      "metadata": {
        "id": "3oGKxFEpBIzC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 224"
      ],
      "metadata": {
        "id": "NsUHRhTXCz7U"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating sequential model\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "# using MobileNetV2 as feature extractor // include_top=False -> discarding last few layers and going to add custom layers for landmark detection\n",
        "mn_v2 = keras.applications.MobileNetV2(input_shape=(224,224,3), include_top=False, weights='imagenet')"
      ],
      "metadata": {
        "id": "SzeOlLLZWq3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(mn_v2)\n",
        "model.add(keras.layers.GlobalAveragePooling2D())\n",
        "model.add(keras.layers.Dropout(0.3))\n",
        "model.add(keras.layers.Dense(136))\n",
        "\n",
        "model.build(input_shape=(None, 224, 224, 3))"
      ],
      "metadata": {
        "id": "FOMRgjrKEBUC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "6MijsIpCHN1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=\"mean_squared_error\", metrics=[\"mae\", \"accuracy\"])\n",
        "\n",
        "chk_path = \"trained_model/model\"\n",
        "model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=chk_path,\n",
        "                                                   monitor=\"val_mae\",\n",
        "                                                   mode=\"auto\",\n",
        "                                                   save_best_only=True,\n",
        "                                                   save_weights_only=True\n",
        "                                                   )"
      ],
      "metadata": {
        "id": "cRuBTxecHX5k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(factor=0.9,\n",
        "                                              monitor=\"val_mae\",\n",
        "                                              mode=\"auto\",\n",
        "                                              cooldown=0,\n",
        "                                              patience=5,\n",
        "                                              verbose=1,\n",
        "                                              min_lr=1e-6\n",
        "                                              )"
      ],
      "metadata": {
        "id": "7X9xqUOwIMDM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_frames, val_frames, train_lm, val_lm = sklearn.model_selection.train_test_split(frames, y_train, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "AmV1JXH3JqFd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=300\n",
        "BATCH_SIZE=32"
      ],
      "metadata": {
        "id": "Js5C7QnhMpr0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train_frames,\n",
        "                  train_lm,\n",
        "                  validation_data=(val_frames, val_lm),\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=EPOCHS,\n",
        "                  callbacks=[model_checkpoint, reduce_lr]\n",
        "                  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAWtSuc1InKd",
        "outputId": "6911c2d8-b0be-4049-df93-64ad29d3ae9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "268/268 [==============================] - 70s 205ms/step - loss: 0.0198 - mae: 0.0889 - accuracy: 0.1000 - val_loss: 9.7530 - val_mae: 3.0380 - val_accuracy: 0.0933 - lr: 0.0010\n",
            "Epoch 2/300\n",
            "268/268 [==============================] - 55s 204ms/step - loss: 0.0053 - mae: 0.0567 - accuracy: 0.1587 - val_loss: 1.9718 - val_mae: 1.3525 - val_accuracy: 0.1449 - lr: 0.0010\n",
            "Epoch 3/300\n",
            "268/268 [==============================] - 56s 207ms/step - loss: 0.0043 - mae: 0.0513 - accuracy: 0.2136 - val_loss: 0.2960 - val_mae: 0.5179 - val_accuracy: 0.3771 - lr: 0.0010\n",
            "Epoch 4/300\n",
            "268/268 [==============================] - 56s 208ms/step - loss: 0.0040 - mae: 0.0494 - accuracy: 0.2656 - val_loss: 0.0868 - val_mae: 0.2768 - val_accuracy: 0.2844 - lr: 0.0010\n",
            "Epoch 5/300\n",
            "268/268 [==============================] - 55s 207ms/step - loss: 0.0039 - mae: 0.0484 - accuracy: 0.3117 - val_loss: 0.0468 - val_mae: 0.2014 - val_accuracy: 0.1732 - lr: 0.0010\n",
            "Epoch 6/300\n",
            "268/268 [==============================] - 56s 207ms/step - loss: 0.0038 - mae: 0.0477 - accuracy: 0.3439 - val_loss: 0.0243 - val_mae: 0.1412 - val_accuracy: 0.4724 - lr: 0.0010\n",
            "Epoch 7/300\n",
            "268/268 [==============================] - 55s 207ms/step - loss: 0.0037 - mae: 0.0471 - accuracy: 0.3653 - val_loss: 0.0133 - val_mae: 0.1000 - val_accuracy: 0.2947 - lr: 0.0010\n",
            "Epoch 8/300\n",
            "268/268 [==============================] - 55s 204ms/step - loss: 0.0036 - mae: 0.0464 - accuracy: 0.3862 - val_loss: 0.0157 - val_mae: 0.1106 - val_accuracy: 0.4658 - lr: 0.0010\n",
            "Epoch 9/300\n",
            "268/268 [==============================] - 55s 206ms/step - loss: 0.0036 - mae: 0.0463 - accuracy: 0.4126 - val_loss: 0.0237 - val_mae: 0.1395 - val_accuracy: 0.4724 - lr: 0.0010\n",
            "Epoch 10/300\n",
            "268/268 [==============================] - 55s 206ms/step - loss: 0.0036 - mae: 0.0461 - accuracy: 0.4075 - val_loss: 0.0286 - val_mae: 0.1549 - val_accuracy: 0.4724 - lr: 0.0010\n",
            "Epoch 11/300\n",
            "268/268 [==============================] - 55s 205ms/step - loss: 0.0035 - mae: 0.0455 - accuracy: 0.4227 - val_loss: 0.0198 - val_mae: 0.1261 - val_accuracy: 0.4605 - lr: 0.0010\n",
            "Epoch 12/300\n",
            "268/268 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0451 - accuracy: 0.4301\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "268/268 [==============================] - 55s 206ms/step - loss: 0.0034 - mae: 0.0451 - accuracy: 0.4301 - val_loss: 0.0198 - val_mae: 0.1268 - val_accuracy: 0.4724 - lr: 0.0010\n",
            "Epoch 13/300\n",
            "268/268 [==============================] - 55s 205ms/step - loss: 0.0034 - mae: 0.0446 - accuracy: 0.4414 - val_loss: 0.0199 - val_mae: 0.1260 - val_accuracy: 0.4724 - lr: 9.0000e-04\n",
            "Epoch 14/300\n",
            "268/268 [==============================] - 55s 206ms/step - loss: 0.0034 - mae: 0.0445 - accuracy: 0.4247 - val_loss: 0.0117 - val_mae: 0.0935 - val_accuracy: 0.4724 - lr: 9.0000e-04\n",
            "Epoch 15/300\n",
            "268/268 [==============================] - 55s 206ms/step - loss: 0.0033 - mae: 0.0442 - accuracy: 0.4519 - val_loss: 0.0091 - val_mae: 0.0804 - val_accuracy: 0.4724 - lr: 9.0000e-04\n",
            "Epoch 16/300\n",
            "268/268 [==============================] - 55s 206ms/step - loss: 0.0033 - mae: 0.0440 - accuracy: 0.4453 - val_loss: 0.0178 - val_mae: 0.1189 - val_accuracy: 0.4724 - lr: 9.0000e-04\n",
            "Epoch 17/300\n",
            "268/268 [==============================] - 55s 206ms/step - loss: 0.0033 - mae: 0.0439 - accuracy: 0.4491 - val_loss: 0.0127 - val_mae: 0.0968 - val_accuracy: 0.1555 - lr: 9.0000e-04\n",
            "Epoch 18/300\n",
            "268/268 [==============================] - 56s 208ms/step - loss: 0.0032 - mae: 0.0435 - accuracy: 0.4586 - val_loss: 0.0070 - val_mae: 0.0671 - val_accuracy: 0.4495 - lr: 9.0000e-04\n",
            "Epoch 19/300\n",
            "268/268 [==============================] - 55s 205ms/step - loss: 0.0032 - mae: 0.0434 - accuracy: 0.4653 - val_loss: 0.0071 - val_mae: 0.0675 - val_accuracy: 0.4724 - lr: 9.0000e-04\n",
            "Epoch 20/300\n",
            "268/268 [==============================] - 55s 205ms/step - loss: 0.0032 - mae: 0.0434 - accuracy: 0.4604 - val_loss: 0.0078 - val_mae: 0.0718 - val_accuracy: 0.4696 - lr: 9.0000e-04\n",
            "Epoch 21/300\n",
            "268/268 [==============================] - 55s 207ms/step - loss: 0.0032 - mae: 0.0432 - accuracy: 0.4432 - val_loss: 0.0052 - val_mae: 0.0560 - val_accuracy: 0.4724 - lr: 9.0000e-04\n",
            "Epoch 22/300\n",
            "268/268 [==============================] - 55s 207ms/step - loss: 0.0032 - mae: 0.0432 - accuracy: 0.4513 - val_loss: 0.0171 - val_mae: 0.1052 - val_accuracy: 0.1002 - lr: 9.0000e-04\n",
            "Epoch 23/300\n",
            "268/268 [==============================] - 56s 207ms/step - loss: 0.0031 - mae: 0.0429 - accuracy: 0.4488 - val_loss: 0.0072 - val_mae: 0.0684 - val_accuracy: 0.4724 - lr: 9.0000e-04\n",
            "Epoch 24/300\n",
            "268/268 [==============================] - 55s 207ms/step - loss: 0.0031 - mae: 0.0428 - accuracy: 0.4609 - val_loss: 0.0057 - val_mae: 0.0597 - val_accuracy: 0.4724 - lr: 9.0000e-04\n",
            "Epoch 25/300\n",
            "268/268 [==============================] - 55s 206ms/step - loss: 0.0031 - mae: 0.0428 - accuracy: 0.4668 - val_loss: 0.0060 - val_mae: 0.0612 - val_accuracy: 0.4724 - lr: 9.0000e-04\n",
            "Epoch 26/300\n",
            "268/268 [==============================] - 56s 207ms/step - loss: 0.0031 - mae: 0.0426 - accuracy: 0.4677 - val_loss: 0.0051 - val_mae: 0.0552 - val_accuracy: 0.4717 - lr: 9.0000e-04\n",
            "Epoch 27/300\n",
            "268/268 [==============================] - 55s 205ms/step - loss: 0.0031 - mae: 0.0426 - accuracy: 0.4580 - val_loss: 0.0280 - val_mae: 0.1381 - val_accuracy: 0.1269 - lr: 9.0000e-04\n",
            "Epoch 28/300\n",
            "268/268 [==============================] - 55s 206ms/step - loss: 0.0031 - mae: 0.0424 - accuracy: 0.4618 - val_loss: 0.0067 - val_mae: 0.0656 - val_accuracy: 0.4610 - lr: 9.0000e-04\n",
            "Epoch 29/300\n",
            "268/268 [==============================] - 55s 205ms/step - loss: 0.0031 - mae: 0.0424 - accuracy: 0.4577 - val_loss: 0.0051 - val_mae: 0.0554 - val_accuracy: 0.4724 - lr: 9.0000e-04\n",
            "Epoch 30/300\n",
            "268/268 [==============================] - 55s 207ms/step - loss: 0.0030 - mae: 0.0420 - accuracy: 0.4695 - val_loss: 0.0045 - val_mae: 0.0519 - val_accuracy: 0.4724 - lr: 9.0000e-04\n",
            "Epoch 31/300\n",
            "268/268 [==============================] - 55s 204ms/step - loss: 0.0030 - mae: 0.0421 - accuracy: 0.4718 - val_loss: 0.0054 - val_mae: 0.0575 - val_accuracy: 0.4377 - lr: 9.0000e-04\n",
            "Epoch 32/300\n",
            " 30/268 [==>...........................] - ETA: 48s - loss: 0.0030 - mae: 0.0422 - accuracy: 0.4865"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_layers=[\n",
        "#     keras.layers.Conv2D( 256, input_shape=( img_size , img_size , 3 ) , kernel_size=( 5 , 5 ) , strides=1 , activation='relu',name=\"input_layer\"),\n",
        "#     keras.layers.Conv2D( 256 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu' ),\n",
        "#     keras.layers.BatchNormalization(),\n",
        "#     keras.layers.Dropout(0.3),\n",
        "    \n",
        "#     keras.layers.Conv2D( 256, kernel_size=( 5 , 5 ) , strides=1 , activation='relu' ),\n",
        "#     keras.layers.Conv2D( 256, kernel_size=( 5 , 5 ) , strides=1 , activation='relu' ),\n",
        "#     keras.layers.BatchNormalization(),\n",
        "#     keras.layers.Dropout(0.3),\n",
        "    \n",
        "#     keras.layers.Conv2D( 200, kernel_size=( 5 , 5 ) , strides=2 , activation='relu'),\n",
        "#     keras.layers.Conv2D( 200 , kernel_size=( 5 , 5 ) , strides= 1, activation='relu'),\n",
        "#     keras.layers.BatchNormalization(),\n",
        "#     keras.layers.Dropout(0.3),\n",
        "    \n",
        "#     keras.layers.Conv2D( 200, kernel_size=( 5 , 5 ) , strides=1 , activation='relu'),\n",
        "#     keras.layers.Conv2D( 200 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu' ),\n",
        "#     keras.layers.BatchNormalization(),\n",
        "#     keras.layers.Dropout(0.3),\n",
        "    \n",
        "#     keras.layers.Conv2D( 170, kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "#     keras.layers.Conv2D( 170, kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "#     keras.layers.BatchNormalization(),\n",
        "#     keras.layers.Dropout(0.3),\n",
        "    \n",
        "#     keras.layers.Conv2D( 136, kernel_size=( 3 , 3 ) , strides=1 , activation='relu'),\n",
        "#     keras.layers.Conv2D( 136, kernel_size=( 3 , 3 ) , strides=2 , activation='relu'),\n",
        "#     keras.layers.BatchNormalization(),\n",
        "#     keras.layers.Dropout(0.3),\n",
        "    \n",
        "#     keras.layers.Conv2D( 136, kernel_size=( 3 , 3 ) , strides=2 , activation='relu'),\n",
        "#     keras.layers.Conv2D( 136 , kernel_size=( 3 , 3 ) , strides=1 , activation='sigmoid'),\n",
        "\n",
        "    \n",
        "# ]\n",
        "# model=keras.Sequential(model_layers)\n",
        "# model.compile( loss= keras.losses.mean_squared_error , optimizer= keras.optimizers.Adam( lr=0.001 ) )\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "CqMG0XoQCEi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = model.fit(frames, y_train, epochs=3, batch_size=32, verbose=2)"
      ],
      "metadata": {
        "id": "Wl1k1f88Cxyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/gdrive/MyDrive/data-v/mymodel')"
      ],
      "metadata": {
        "id": "Rjg6ivj4C6bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('/content/gdrive/MyDrive/data-v/mymodel')"
      ],
      "metadata": {
        "id": "EKTFFejlORNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_frames = np.load('/content/gdrive/MyDrive/data-v/test_frames.npy')"
      ],
      "metadata": {
        "id": "vSysxpLW8Ok1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, arr = plt.subplots(6,5,figsize=(20,20))\n",
        "\n",
        "for i in range(1, 30):\n",
        "  r = i // 5\n",
        "  c = i % 5\n",
        "\n",
        "  sam = test_frames[i]\n",
        "  pred = model.predict( test_frames[ i : i +1  ] ) \n",
        "  x=np.reshape(pred[:,:,:,np.arange(0,136,2)],(68))*img_size\n",
        "  y=np.reshape(pred[:,:,:,np.arange(1,136,2)],(68))*img_size\n",
        "  arr[r][c].imshow(sam)\n",
        "  arr[r][c].scatter( x,y, c='yellow',s=6)"
      ],
      "metadata": {
        "id": "O5QFbVIXPLnZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}