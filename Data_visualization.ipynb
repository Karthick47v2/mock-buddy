{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthick47v2/mock-buddy/blob/main/Data_visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install kaggle\n",
        "!pip3 install kaggle\n",
        "\n",
        "# copy kaggle.json to required dir and give permission\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "mDAeJniUT6HX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "!kaggle datasets download selfishgene/youtube-faces-with-facial-keypoints"
      ],
      "metadata": {
        "id": "z45P-k0lUK57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip\n",
        "!unzip youtube-faces-with-facial-keypoints.zip"
      ],
      "metadata": {
        "id": "WOGRYJ0jUwlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import libs\n",
        "# data visualization\n",
        "import pandas as pd\n",
        "# easy file access\n",
        "import glob\n",
        "# np array\n",
        "import numpy as np\n",
        "# plot\n",
        "import matplotlib.pyplot as plt\n",
        "# image processing\n",
        "import cv2"
      ],
      "metadata": {
        "id": "6dS9jx6LVgO-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read csv\n",
        "csv_file = pd.read_csv('/content/youtube_faces_with_keypoints_full.csv')"
      ],
      "metadata": {
        "id": "7e_YpgxwWmYs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file.head(10)"
      ],
      "metadata": {
        "id": "IeUXsctGWsOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total videos : \", csv_file.shape[0])\n",
        "print(\"Unique videos : \", len(csv_file['personName'].unique()))"
      ],
      "metadata": {
        "id": "gee44HmOWuev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure there are no unwanted npz files in the directory coz we are going to search the whole dir for npz files\n",
        "# using iglob to prevent unnecessary load to RAM\n",
        "npz_path_list = glob.glob('/content/**/*.npz', recursive=True)"
      ],
      "metadata": {
        "id": "z0XR8KZyXthm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get all video id\n",
        "# npzPathList contains path -> xxxx/xxxx/xxx/yyy.npz....we need yyy ...\n",
        "# inorder to get that\n",
        "# get yyy.npz (split by '/' and get last element)\n",
        "# get yyy (split by '.' and get 1st element)\n",
        "vidIDs = [x.split('/')[-1].split('.')[0] for x in npz_path_list]"
      ],
      "metadata": {
        "id": "11iT_nZgcMHG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now map video id with full path (csv contains vidID so we need it to map with path)\n",
        "vid_paths = {}\n",
        "\n",
        "for vidID, vid_path in zip(vidIDs, npz_path_list):\n",
        "  vid_paths[vidID] = vid_path"
      ],
      "metadata": {
        "id": "c8ZxjDUXc7ck"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# just making sure no data is missing\n",
        "csv_file = csv_file.loc[csv_file.loc[:, 'videoID'].isin(vid_paths.keys()), :].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "AizK-FDne31H"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get hands-on the data AKA play with data\n",
        "# visualize 4 frames of 4 different videos with landmarks\n",
        "np.random.seed(42)\n",
        "num_vids = 4\n",
        "num_frames = 4\n",
        "frames_list = np.array([0.1, 0.3, 0.6, 0.9])\n",
        "\n",
        "# get rand vid ids\n",
        "sample_vids = csv_file.loc[np.random.choice(csv_file.index, size=num_vids, replace=False), 'videoID']"
      ],
      "metadata": {
        "id": "AjJBU9G7hyhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize data using matplotlib\n",
        "fig, arr = plt.subplots(nrows=num_vids, ncols=num_frames, figsize=(14,18))\n",
        "\n",
        "for i, videoID in enumerate(sample_vids):\n",
        "  # load nparray\n",
        "  np_file = np.load(vid_paths[videoID])\n",
        "  # it contains colorimages, boundingbox, landmarks2D\n",
        "  # color image shape is 4 (x, y, RGB, no_of_frames)\n",
        "  col_img = np_file['colorImages']\n",
        "  landmarks = np_file['landmarks2D']\n",
        "\n",
        "  # generate color image from np array (uin8 -> 0 - 255)\n",
        "  frames = (frames_list * (col_img.shape[3] - 1)).astype(np.uint8)\n",
        "\n",
        "  # generate image, landmarks\n",
        "  for j, frame in enumerate(frames):\n",
        "    arr[i][j].imshow(col_img[:, :, :, frame])\n",
        "    arr[i][j].scatter(x=landmarks[:,0,frame], y=landmarks[:, 1, frame], s=3, c='r')"
      ],
      "metadata": {
        "id": "SjpFpw0CkA9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save resized images and resized landmarks separately for future usage\n",
        "# total 2194 -- but i am taking 2000 video files and getting each 45th frame from each video (0, 45, 90..)\n",
        "# so total training datatset length ~ 6350 (192x192x3 np format)\n",
        "frames = []\n",
        "landmark_xy = []\n",
        "img_size = 192     # resize all frames to 192 x 192\n",
        "frame_cut = 45\n",
        "\n",
        "for i, vidID in enumerate(csv_file['videoID']):\n",
        "  # as it contains each frames of video, we can omit many frames \n",
        "  # here i am only using 1 frame per video\n",
        "\n",
        "  if i == 2000:\n",
        "    break\n",
        "\n",
        "  np_file = np.load(vid_paths[vidID])\n",
        "  col_img = np_file['colorImages']\n",
        "  landmarks2D = np_file['landmarks2D']\n",
        "  \n",
        "  n = int(((col_img.shape[3] - 1) / frame_cut) + 1)\n",
        "  for j in range(n):\n",
        "    frame_h, frame_w = col_img[:, :, :, j * frame_cut].shape[:2]\n",
        "    scale_h, scale_w = img_size / frame_h, img_size / frame_w\n",
        "\n",
        "    landmarks = landmarks2D[:, :, j * frame_cut]\n",
        "    landmarks[:, 0] = landmarks[:, 0] * scale_w\n",
        "    landmarks[:, 1] = landmarks[:, 1] * scale_h \n",
        "    landmark_xy.append(landmarks)\n",
        "\n",
        "    frames.append(cv2.resize(col_img[:, :, :, j * frame_cut], (img_size, img_size)) / 255)\n",
        "\n",
        "frames = np.array(frames)\n",
        "landmark_xy = np.array(landmark_xy)"
      ],
      "metadata": {
        "id": "Jaoru-6Ol-oC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# arrage to model train format\n",
        "y_data = landmark_xy.reshape(landmark_xy.shape[0], -1)\n",
        "y_train = np.reshape(y_data, (-1, 1, 1, 136)) / img_size"
      ],
      "metadata": {
        "id": "cRyEuhu0zRK3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check \n",
        "fig, arr = plt.subplots(nrows=1, ncols=4, figsize=(15,15))\n",
        "\n",
        "for i in range(4):\n",
        "  arr[i].imshow(frames[i])\n",
        "  x = np.reshape(y_train[i, :, :, np.arange(0, 136, 2)], (68)) * img_size\n",
        "  y = np.reshape(y_train[i, :, :, np.arange(1, 136, 2)], (68)) * img_size\n",
        "  arr[i].scatter(x, y, s=3, c='r')"
      ],
      "metadata": {
        "id": "8a2sWsCf4L5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save np array for future use (training model)\n",
        "np.save('frames45.npy', frames)\n",
        "np.save('y_train45.npy', y_train)"
      ],
      "metadata": {
        "id": "hQF1RthA5sTh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# move the saved files to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "Q8PIzHyr75vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv y_train45.npy frames45.npy /content/gdrive/MyDrive/data-v/"
      ],
      "metadata": {
        "id": "J4qxHFfr8G6q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save resized images and resized landmarks separately for test dataset\n",
        "# here taking only 1 frame from each vid file. (upto 100 vids)\n",
        "test_frames = []\n",
        "test_bbox = []\n",
        "img_size = 192     # resize all frames to 192 x 192\n",
        "\n",
        "for i, vidID in enumerate(csv_file['videoID']):\n",
        "  # as it contains each frames of video, we can omit many frames \n",
        "  # here i am only using 1 frame per video\n",
        "\n",
        "  if i == 100:\n",
        "    break\n",
        "\n",
        "  np_file = np.load(vid_paths[vidID])\n",
        "  col_img = np_file['colorImages']\n",
        "  bbox = np_file['boundingBox']\n",
        "  frame_h, frame_w = col_img[:, :, :, 0].shape[:2]\n",
        "  scale_h, scale_w = img_size / frame_h, img_size / frame_w\n",
        "\n",
        "  box = bbox[:,:,3]\n",
        "  box[:,0] = box[:,0] * scale_w\n",
        "  box[:,1] = box[:,1] * scale_h\n",
        "  test_bbox.append(box)\n",
        "\n",
        "  test_frames.append(cv2.resize(col_img[:, :, :, 3], (img_size, img_size)) / 255)\n",
        "\n",
        "test_frames = np.array(test_frames)\n",
        "test_bbox = np.array(test_bbox)"
      ],
      "metadata": {
        "id": "q6YwZ4Jc8qI2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,arr = plt.subplots(nrows=1,ncols=4,figsize=(15,15))\n",
        "for i in range(4):\n",
        "    arr[i].imshow(test_frames[i])\n",
        "    arr[i].scatter(test_bbox[i,:,0],test_bbox[i,:,1],s=5)\n",
        "\n"
      ],
      "metadata": {
        "id": "E-Q_QTBuTpdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save np array for future use (testing model)\n",
        "np.save('test_frames.npy', test_frames)\n",
        "np.save('test_bbox.npy', test_bbox)"
      ],
      "metadata": {
        "id": "mWW5C-UX7b3Q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv test_frames.npy test_bbox.npy /content/gdrive/MyDrive/data-v/"
      ],
      "metadata": {
        "id": "kL5IW1M87bzy"
      },
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Data visualization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPaFmk0Ka+8sSgc4SjYWNdi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}