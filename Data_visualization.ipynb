{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthick47v2/mock-buddy/blob/main/Data_visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install kaggle\n",
        "!pip3 install kaggle\n",
        "\n",
        "# copy kaggle.json to required dir and give permission\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "mDAeJniUT6HX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "!kaggle datasets download selfishgene/youtube-faces-with-facial-keypoints"
      ],
      "metadata": {
        "id": "z45P-k0lUK57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip\n",
        "!unzip youtube-faces-with-facial-keypoints.zip"
      ],
      "metadata": {
        "id": "WOGRYJ0jUwlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import libs\n",
        "# data visualization\n",
        "import pandas as pd\n",
        "# easy file access\n",
        "import glob\n",
        "# np array\n",
        "import numpy as np\n",
        "# plot\n",
        "import matplotlib.pyplot as plt\n",
        "# image processing\n",
        "import cv2"
      ],
      "metadata": {
        "id": "6dS9jx6LVgO-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read csv\n",
        "csv_file = pd.read_csv('/content/youtube_faces_with_keypoints_full.csv')"
      ],
      "metadata": {
        "id": "7e_YpgxwWmYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file.head(10)"
      ],
      "metadata": {
        "id": "IeUXsctGWsOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total videos : \", csv_file.shape[0])\n",
        "print(\"Unique videos : \", len(csv_file['personName'].unique()))"
      ],
      "metadata": {
        "id": "gee44HmOWuev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure there are no unwanted npz files in the directory coz we are going to search the whole dir for npz files\n",
        "# using iglob to prevent unnecessary load to RAM\n",
        "npz_path_list = glob.glob('/content/**/*.npz', recursive=True)"
      ],
      "metadata": {
        "id": "z0XR8KZyXthm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get all video id\n",
        "# npzPathList contains path -> xxxx/xxxx/xxx/yyy.npz....we need yyy ...\n",
        "# inorder to get that\n",
        "# get yyy.npz (split by '/' and get last element)\n",
        "# get yyy (split by '.' and get 1st element)\n",
        "vidIDs = [x.split('/')[-1].split('.')[0] for x in npz_path_list]"
      ],
      "metadata": {
        "id": "11iT_nZgcMHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now map video id with full path (csv contains vidID so we need it to map with path)\n",
        "vid_paths = {}\n",
        "\n",
        "for vidID, vid_path in zip(vidIDs, npz_path_list):\n",
        "  vid_paths[vidID] = vid_path"
      ],
      "metadata": {
        "id": "c8ZxjDUXc7ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# just making sure no data is missing\n",
        "csv_file = csv_file.loc[csv_file.loc[:, 'videoID'].isin(vid_paths.keys()), :].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "AizK-FDne31H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get hands-on the data AKA play with data\n",
        "# visualize 4 frames of 4 different videos with landmarks\n",
        "np.random.seed(42)\n",
        "num_vids = 4\n",
        "num_frames = 4\n",
        "frames_list = np.array([0.1, 0.3, 0.6, 0.9])\n",
        "\n",
        "# get rand vid ids\n",
        "sample_vids = csv_file.loc[np.random.choice(csv_file.index, size=num_vids, replace=False), 'videoID']"
      ],
      "metadata": {
        "id": "AjJBU9G7hyhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets see the size of single frame and landmarks obj\n",
        "for i, vidID in enumerate(csv_file['videoID']):\n",
        "  if i == 1:\n",
        "    break\n",
        "\n",
        "  np_file = np.load(vid_paths[vidID])\n",
        "  col_img = np_file['colorImages']\n",
        "  landmarks2D = np_file['landmarks2D']\n",
        "  \n",
        "  frame_h, frame_w = col_img[:, :, :, 0].shape[:2]\n",
        "  scale_h, scale_w = 192 / frame_h, 192 / frame_w\n",
        "\n",
        "  landmarks = landmarks2D[:, :, 0]\n",
        "  landmarks[:, 0] = landmarks[:, 0] * scale_w\n",
        "  landmarks[:, 1] = landmarks[:, 1] * scale_h \n",
        "  landmarks = landmarks.astype(np.float32)\n",
        "  print(landmarks.size, landmarks.itemsize, landmarks.size * landmarks.itemsize, 'bytes')\n",
        "\n",
        "  frames = (cv2.resize(col_img[:, :, :, 0], (192, 192))).astype(np.uint8)\n",
        "  print(frames.size, frames.itemsize, frames.size * frames.itemsize, 'bytes')"
      ],
      "metadata": {
        "id": "27SnkBb4TqB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize data using matplotlib\n",
        "fig, arr = plt.subplots(nrows=num_vids, ncols=num_frames, figsize=(14,18))\n",
        "\n",
        "for i, videoID in enumerate(sample_vids):\n",
        "  # load nparray\n",
        "  np_file = np.load(vid_paths[videoID])\n",
        "  # it contains colorimages, boundingbox, landmarks2D\n",
        "  # color image shape is 4 (x, y, RGB, no_of_frames)\n",
        "  col_img = np_file['colorImages']\n",
        "  landmarks = np_file['landmarks2D']\n",
        "\n",
        "  # generate color image from np array (uin8 -> 0 - 255)\n",
        "  frames = (frames_list * (col_img.shape[3] - 1)).astype(np.uint8)\n",
        "\n",
        "  # generate image, landmarks\n",
        "  for j, frame in enumerate(frames):\n",
        "    arr[i][j].imshow(col_img[:, :, :, frame])\n",
        "    arr[i][j].scatter(x=landmarks[:,0,frame], y=landmarks[:, 1, frame], s=3, c='r')"
      ],
      "metadata": {
        "id": "SjpFpw0CkA9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save resized images and resized landmarks separately for future usage\n",
        "# total 2194 -- but i am taking 2000 video files and getting each 45th frame from each video (0, 45, 90..)\n",
        "# so total training datatset length ~ 6350 (224x224x3 np format)\n",
        "frames = []\n",
        "landmark_xy = []\n",
        "img_size = 224     # resize all frames to 224 x 224\n",
        "frame_cut = 30\n",
        "\n",
        "for i, vidID in enumerate(csv_file['videoID']):\n",
        "  # as it contains each frames of video, we can omit many frames \n",
        "  # here i am only using 1 frame per video\n",
        "\n",
        "  np_file = np.load(vid_paths[vidID])\n",
        "  col_img = np_file['colorImages']\n",
        "  landmarks2D = np_file['landmarks2D']\n",
        "  \n",
        "  n = int(((col_img.shape[3] - 1) / frame_cut) + 1)\n",
        "  for j in range(n):\n",
        "    frame_h, frame_w = col_img[:, :, :, j * frame_cut].shape[:2]\n",
        "    scale_h, scale_w = img_size / frame_h, img_size / frame_w\n",
        "\n",
        "    landmarks = landmarks2D[:, :, j * frame_cut]\n",
        "    landmarks[:, 0] = landmarks[:, 0] * scale_w\n",
        "    landmarks[:, 1] = landmarks[:, 1] * scale_h \n",
        "    landmark_xy.append(landmarks.astype(np.float32))\n",
        "\n",
        "    frames.append(cv2.resize(col_img[:, :, :, j * frame_cut], (img_size, img_size)).astype(np.uint8))\n",
        "\n",
        "frames = np.array(frames).astype(np.uint8)\n",
        "landmark_xy = np.array(landmark_xy).astype(np.float32)"
      ],
      "metadata": {
        "id": "Jaoru-6Ol-oC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# arrage to model train format\n",
        "y_data = landmark_xy.reshape(landmark_xy.shape[0], -1)\n",
        "y_train = np.reshape(y_data, (-1, 1, 1, 136)) / img_size"
      ],
      "metadata": {
        "id": "cRyEuhu0zRK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check \n",
        "fig, arr = plt.subplots(nrows=1, ncols=4, figsize=(15,15))\n",
        "\n",
        "for i in range(4):\n",
        "  arr[i].imshow(frames[i])\n",
        "  x = np.reshape(y_train[i, :, :, np.arange(0, 136, 2)], (68)) * img_size\n",
        "  y = np.reshape(y_train[i, :, :, np.arange(1, 136, 2)], (68)) * img_size\n",
        "  arr[i].scatter(x, y, s=3, c='r')"
      ],
      "metadata": {
        "id": "8a2sWsCf4L5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save np array for future use (training model)\n",
        "np.save('frames30.npy', frames)\n",
        "np.save('y_train30.npy', y_train)"
      ],
      "metadata": {
        "id": "hQF1RthA5sTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# move the saved files to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "Q8PIzHyr75vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv y_train30.npy frames30.npy /content/gdrive/MyDrive/data-v/"
      ],
      "metadata": {
        "id": "J4qxHFfr8G6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save resized images and resized landmarks separately for test dataset\n",
        "# here taking only 1 frame from each vid file. (upto 100 vids)\n",
        "test_frames = []\n",
        "test_bbox = []\n",
        "img_size = 224     # resize all frames to 224 x 224\n",
        "\n",
        "for i, vidID in enumerate(csv_file['videoID']):\n",
        "  # as it contains each frames of video, we can omit many frames \n",
        "  # here i am only using 1 frame per video\n",
        "\n",
        "  if i == 100:\n",
        "    break\n",
        "\n",
        "  np_file = np.load(vid_paths[vidID])\n",
        "  col_img = np_file['colorImages']\n",
        "  frame_h, frame_w = col_img[:, :, :, 0].shape[:2]\n",
        "  scale_h, scale_w = img_size / frame_h, img_size / frame_w\n",
        "\n",
        "  test_frames.append(cv2.resize(col_img[:, :, :, 3], (img_size, img_size)).astype(np.uint8))\n",
        "\n",
        "test_frames = np.array(test_frames).astype(np.uint8)"
      ],
      "metadata": {
        "id": "q6YwZ4Jc8qI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,arr = plt.subplots(nrows=1,ncols=4,figsize=(15,15))\n",
        "for i in range(4):\n",
        "    arr[i].imshow(test_frames[i])\n",
        "\n"
      ],
      "metadata": {
        "id": "E-Q_QTBuTpdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save np array for future use (testing model)\n",
        "np.save('test_frames.npy', test_frames)"
      ],
      "metadata": {
        "id": "mWW5C-UX7b3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv test_frames.npy /content/gdrive/MyDrive/data-v/"
      ],
      "metadata": {
        "id": "kL5IW1M87bzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###################### IMAGE AUGMENTATION ############################"
      ],
      "metadata": {
        "id": "oJEnF-J91Wi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.load('/content/gdrive/MyDrive/data-v/y_train30.npy')\n",
        "frames = np.load('/content/gdrive/MyDrive/data-v/frames30.npy')"
      ],
      "metadata": {
        "id": "YqkkDqN9jLiy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot for debugging\n",
        "def plot_sample(frame, keypoint, axis):\n",
        "    axis.imshow(frame)\n",
        "    x = np.reshape(keypoint[:, :, np.arange(0, 136, 2)], (68)) * img_size\n",
        "    y = np.reshape(keypoint[:, :, np.arange(1, 136, 2)], (68)) * img_size\n",
        "    axis.scatter(x, y, s=3, c='r')"
      ],
      "metadata": {
        "id": "6JwqKc8l1cfM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# randomly picking 25 % of train data to create each augmentations \n",
        "random_flip_images = np.random.choice(np.arange(frames.shape[0]), size=int(frames.shape[0] * 0.25), replace=False)\n",
        "random_shift_images = np.random.choice(np.arange(frames.shape[0]), size=int(frames.shape[0] * 0.25), replace=False)"
      ],
      "metadata": {
        "id": "0MCJ0BdF1vgM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flipping horizontally (both frame and keypoint)\n",
        "def horizontal_flip(frame, keypoints):\n",
        "    flipped_keypoints = []\n",
        "    flipped_frame = np.flip(frame, axis=2)   # flip col wise\n",
        "    for idx, sample_keypoints in enumerate(keypoints):\n",
        "        flipped_keypoints.append([[[1.-coor if idxx%2==0 else coor for idxx,coor in enumerate(sample_keypoints[0][0])]]]) # idxx%2 == 0 will be all horizontal keypoints so flipping them only\n",
        "    flipped_keypoints = np.array(flipped_keypoints)\n",
        "    return flipped_frame, flipped_keypoints\n",
        "\n",
        "flipped_train_frames, flipped_train_keypoints = horizontal_flip(frames[random_flip_images, :, :, :], y_train[random_flip_images, :, :, :])\n",
        "\n",
        "# joining with train data\n",
        "frames = np.concatenate((frames, flipped_train_frames))\n",
        "y_train = np.concatenate((y_train, flipped_train_keypoints))\n",
        "\n",
        "fig, axis = plt.subplots()\n",
        "plot_sample(flipped_train_frames[0], flipped_train_keypoints[0], axis) "
      ],
      "metadata": {
        "id": "_Pd7uXDn1kKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shifting 36 px each side -- 36 is arbitary value\n",
        "def shift_images(images, keypoints):\n",
        "    pixel_shifts = [36]\n",
        "    shifted_images = []\n",
        "    shifted_keypoints = []\n",
        "    for shift in pixel_shifts:    # augmenting over several pixel shift values\n",
        "        for (shift_x, shift_y) in [(-shift, -shift), (-shift, shift), (shift, -shift), (shift, shift)]:\n",
        "            M = np.float32([[1, 0, shift_x], [0, 1, shift_y]])\n",
        "            for image, keypoint in zip(images, keypoints):\n",
        "                shifted_image = cv2.warpAffine(image, M, (224,224), flags=cv2.INTER_CUBIC)  # affine transformation\n",
        "                shifted_keypoint = np.array([[[(point+shift_x/224) if idx%2==0 else (point+shift_y/224) for idx, point in enumerate(keypoint[0][0])]]])\n",
        "                if np.all(0.0<shifted_keypoint) and np.all(shifted_keypoint<1.0):   # check if all values are inside 1 (Normalized keypoint) or else clip later\n",
        "                    shifted_images.append(shifted_image.reshape(224,224,3))\n",
        "                    shifted_keypoints.append(shifted_keypoint)\n",
        "    shifted_keypoints = np.clip(shifted_keypoints,0.0,1.0)\n",
        "    shifted_images = np.array(shifted_images)\n",
        "    return shifted_images, shifted_keypoints\n",
        "\n",
        "shifted_train_images, shifted_train_keypoints = shift_images(frames[random_shift_images, :, :, :], y_train[random_shift_images, :, :, :])\n",
        "\n",
        "# joining with train data\n",
        "frames = np.concatenate((frames, shifted_train_images))\n",
        "y_train = np.concatenate((y_train, shifted_train_keypoints))\n",
        "\n",
        "fig, axis = plt.subplots()\n",
        "plot_sample(shifted_train_images[1], shifted_train_keypoints[1], axis)"
      ],
      "metadata": {
        "id": "vYCZTrvm11r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save np array for future use (training model)\n",
        "np.save('frames30_AUG.npy', frames)\n",
        "np.save('y_train30_AUG.npy', y_train)\n",
        "\n",
        "\n",
        "## from 9k to 21k"
      ],
      "metadata": {
        "id": "2PAHmr7h5G_a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jjIGhLts6J1b"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Data visualization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMVI3rg8zpDgWUQq9ZZwCM9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}